{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed modules\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open excel file and read the data\n",
    "\n",
    "folder = r'C:/folder'\n",
    "path = folder + '/Path_analysis.xlsx'\n",
    "\n",
    "group_a = pd.read_excel(path, sheet_name = 'A', header = 0, usecols = \"E,F,H,K:M,O,U\")\n",
    "group_b = pd.read_excel(path, sheet_name = 'B', header = 0, usecols = \"E,F,H,K:M,O,U\")\n",
    "compare = pd.read_excel(path, sheet_name = 'compare', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression data preparation - group a:\n",
    "# a5 - all points of group a, fixed values, ranks and stairs\n",
    "colnames = ['Angle_val - fixed', 'Slope_val', 'Dist_val - fixed', 'Angle_#', 'Slope_#', 'Dist_#', 'Stairs', 'Chosen']\n",
    "set_a5 = group_a[colnames]\n",
    "\n",
    "# a4 - all points of group a, fixed values and ranks\n",
    "set_a4 = set_a5.drop(columns = ['Stairs'])\n",
    "set_a4 = set_a4.drop(columns = ['Dist_val - fixed', 'Dist_#'])\n",
    "\n",
    "# a3 - all points of group a, ranks and stairs\n",
    "set_a3 = set_a5.drop(columns = ['Angle_val - fixed','Slope_val','Dist_val - fixed'])\n",
    "set_a3 = set_a3.drop(columns = ['Dist_#'])\n",
    "\n",
    "# a2 - all points of group a, ranks\n",
    "set_a2 = set_a5.drop(columns = ['Angle_val - fixed','Slope_val','Dist_val - fixed', 'Stairs'])\n",
    "set_a2 = set_a2.drop(columns = ['Dist_#'])\n",
    "\n",
    "# a1 - all points of group a, fixed values and stairs\n",
    "set_a1 = set_a5.drop(columns = ['Angle_#','Slope_#','Dist_#'])\n",
    "set_a1 = set_a1.drop(columns = ['Dist_val - fixed'])\n",
    "\n",
    "# a0 - all points of group a, fixed values\n",
    "set_a0 = set_a5.drop(columns = ['Angle_#','Slope_#','Dist_#','Stairs'])\n",
    "set_a0 = set_a0.drop(columns = ['Dist_val - fixed'])\n",
    "\n",
    "set_a5 = set_a5.drop(columns = ['Dist_val - fixed', 'Dist_#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression data preparation - group b:\n",
    "# b5 - all points of group b, fixed values, ranks and stairs\n",
    "colnames = ['Angle_val - fixed', 'Slope_val', 'Dist_val - fixed', 'Angle_#', 'Slope_#', 'Dist_#', 'Stairs', 'Chosen']\n",
    "set_b5 = group_b[colnames]\n",
    "\n",
    "# b4 - all points of group b, fixed values and ranks\n",
    "set_b4 = set_b5.drop(columns = ['Stairs'])\n",
    "set_b4 = set_b4.drop(columns = ['Dist_val - fixed', 'Dist_#'])\n",
    "\n",
    "# b3 - all points of group b, ranks and stairs\n",
    "set_b3 = set_b5.drop(columns = ['Angle_val - fixed','Slope_val','Dist_val - fixed'])\n",
    "set_b3 = set_b3.drop(columns = ['Dist_#'])\n",
    "\n",
    "# b2 - all points of group b, ranks\n",
    "set_b2 = set_b5.drop(columns = ['Angle_val - fixed','Slope_val','Dist_val - fixed', 'Stairs'])\n",
    "set_b2 = set_b2.drop(columns = ['Dist_#'])\n",
    "\n",
    "# b1 - all points of group b, fixed values and stairs\n",
    "set_b1 = set_b5.drop(columns = ['Angle_#','Slope_#','Dist_#'])\n",
    "set_b1 = set_b1.drop(columns = ['Dist_val - fixed'])\n",
    "\n",
    "# b0 - all points of group b, fixed values\n",
    "set_b0 = set_b5.drop(columns = ['Angle_#','Slope_#','Dist_#','Stairs'])\n",
    "set_b0 = set_b0.drop(columns = ['Dist_val - fixed'])\n",
    "\n",
    "set_b5 = set_b5.drop(columns = ['Dist_val - fixed', 'Dist_#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression data preparation - unified:\n",
    "# 5 - all points of both groups, fixed values, ranks and stairs\n",
    "set_5 = group_a.append(group_b, ignore_index = True)\n",
    "colnames = ['Angle_val - fixed', 'Slope_val', 'Dist_val - fixed', 'Angle_#', 'Slope_#', 'Dist_#', 'Stairs', 'Chosen']\n",
    "set_5 = set_5[colnames]\n",
    "\n",
    "# 4 - all points of both groups, fixed values and ranks\n",
    "set_4 = set_5.drop(columns = ['Stairs'])\n",
    "set_4 = set_4.drop(columns = ['Dist_val - fixed', 'Dist_#'])\n",
    "\n",
    "# 3 - all points of both groups, ranks and stairs\n",
    "set_3 = set_5.drop(columns = ['Angle_val - fixed','Slope_val','Dist_val - fixed'])\n",
    "set_3 = set_3.drop(columns = ['Dist_#'])\n",
    "\n",
    "# 2 - all points of both groups, ranks\n",
    "set_2 = set_5.drop(columns = ['Angle_val - fixed','Slope_val','Dist_val - fixed', 'Stairs'])\n",
    "set_2 = set_2.drop(columns = ['Dist_#'])\n",
    "\n",
    "# 1 - all points of both groups, fixed values and stairs\n",
    "set_1 = set_5.drop(columns = ['Angle_#','Slope_#','Dist_#'])\n",
    "set_1 = set_1.drop(columns = ['Dist_val - fixed'])\n",
    "\n",
    "# 0 - all points of both groups, fixed values\n",
    "set_0 = set_5.drop(columns = ['Angle_#','Slope_#','Dist_#','Stairs'])\n",
    "set_0 = set_0.drop(columns = ['Dist_val - fixed'])\n",
    "\n",
    "set_5 = set_5.drop(columns = ['Dist_val - fixed', 'Dist_#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logistic regression solver 5 - group a\n",
    "\n",
    "# scale training data\n",
    "X_a5 = set_a5.drop(columns = ['Chosen'])\n",
    "scaler_a5 = StandardScaler()\n",
    "X_a5 = scaler_a5.fit_transform(X_a5)\n",
    "y_a5 = set_a5.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_a5_train, X_a5_test, y_a5_train, y_a5_test = train_test_split(X_a5, y_a5, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_a5 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_a5.fit(X_a5_train, y_a5_train)\n",
    "\n",
    "# y_pred_a5 = reg_a5.predict(X_a5_test)\n",
    "print(reg_a5.score(X_a5_test, y_a5_test))\n",
    "print(reg_a5.coef_)\n",
    "print(reg_a5.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 5 - group b\n",
    "\n",
    "# scale training data\n",
    "X_b5 = set_b5.drop(columns = ['Chosen'])\n",
    "scaler_b5 = StandardScaler()\n",
    "X_b5 = scaler_a5.fit_transform(X_b5)\n",
    "y_b5 = set_b5.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_b5_train, X_b5_test, y_b5_train, y_b5_test = train_test_split(X_b5, y_b5, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_b5 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_b5.fit(X_b5_train, y_b5_train)\n",
    "\n",
    "# y_pred_b5 = reg_b5.predict(X_b5_test)\n",
    "print(reg_b5.score(X_b5_test, y_b5_test))\n",
    "print(reg_b5.coef_)\n",
    "print(reg_b5.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 5 - unified\n",
    "\n",
    "# scale training data\n",
    "X_5 = set_5.drop(columns = ['Chosen'])\n",
    "scaler_5 = StandardScaler()\n",
    "X_5 = scaler_5.fit_transform(X_5)\n",
    "y_5 = set_5.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(X_5, y_5, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_5 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_5.fit(X_5_train, y_5_train)\n",
    "\n",
    "# y_pred_5 = reg_5.predict(X_5_test)\n",
    "print(reg_5.score(X_5_test, y_5_test))\n",
    "print(reg_5.coef_)\n",
    "print(reg_5.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 4 - group a\n",
    "\n",
    "# scale training data\n",
    "X_a4 = set_a4.drop(columns = ['Chosen'])\n",
    "scaler_a4 = StandardScaler()\n",
    "X_a4 = scaler_a4.fit_transform(X_a4)\n",
    "y_a4 = set_a4.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_a4_train, X_a4_test, y_a4_train, y_a4_test = train_test_split(X_a4, y_a4, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_a4 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_a4.fit(X_a4_train, y_a4_train)\n",
    "\n",
    "# y_pred_a4 = reg_a4.predict(X_a4_test)\n",
    "print(reg_a4.score(X_a4_test, y_a4_test))\n",
    "print(reg_a4.coef_)\n",
    "print(reg_a4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 4 - group b\n",
    "\n",
    "# scale training data\n",
    "X_b4 = set_b4.drop(columns = ['Chosen'])\n",
    "scaler_b4 = StandardScaler()\n",
    "X_b4 = scaler_b4.fit_transform(X_b4)\n",
    "y_b4 = set_b4.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_b4_train, X_b4_test, y_b4_train, y_b4_test = train_test_split(X_b4, y_b4, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_b4 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_b4.fit(X_b4_train, y_b4_train)\n",
    "\n",
    "# y_pred_b4 = reg_b4.predict(X_b4_test)\n",
    "print(reg_b4.score(X_b4_test, y_b4_test))\n",
    "print(reg_b4.coef_)\n",
    "print(reg_b4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 4 - unified\n",
    "\n",
    "# scale training data\n",
    "X_4 = set_4.drop(columns = ['Chosen'])\n",
    "scaler_4 = StandardScaler()\n",
    "X_4 = scaler_4.fit_transform(X_4)\n",
    "y_4 = set_4.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_4_train, X_4_test, y_4_train, y_4_test = train_test_split(X_4, y_4, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_4 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_4.fit(X_4_train, y_4_train)\n",
    "\n",
    "# y_pred_4 = reg_4.predict(X_4_test)\n",
    "print(reg_4.score(X_4_test, y_4_test))\n",
    "print(reg_4.coef_)\n",
    "print(reg_4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 3 - group a\n",
    "\n",
    "# scale training data\n",
    "X_a3 = set_a3.drop(columns = ['Chosen'])\n",
    "scaler_a3 = StandardScaler()\n",
    "X_a3 = scaler_a3.fit_transform(X_a3)\n",
    "y_a3 = set_a3.Chosen\n",
    "# prepare training and testing samples\n",
    "X_a3_train, X_a3_test, y_a3_train, y_a3_test = train_test_split(X_a3, y_a3, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_a3 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_a3.fit(X_a3_train, y_a3_train)\n",
    "\n",
    "# y_pred_a3 = reg_a3.predict(X_a3_test)\n",
    "print(reg_a3.score(X_a3_test, y_a3_test))\n",
    "print(reg_a3.coef_)\n",
    "print(reg_a3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 3 - group b\n",
    "\n",
    "# scale training data\n",
    "X_b3 = set_b3.drop(columns = ['Chosen'])\n",
    "scaler_b3 = StandardScaler()\n",
    "X_b3 = scaler_b3.fit_transform(X_b3)\n",
    "y_b3 = set_b3.Chosen\n",
    "# prepare training and testing samples\n",
    "X_b3_train, X_b3_test, y_b3_train, y_b3_test = train_test_split(X_b3, y_b3, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_b3 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_b3.fit(X_b3_train, y_b3_train)\n",
    "\n",
    "# y_pred_b3 = reg_b3.predict(X_b3_test)\n",
    "print(reg_b3.score(X_b3_test, y_b3_test))\n",
    "print(reg_b3.coef_)\n",
    "print(reg_b3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 3 - unified\n",
    "\n",
    "# scale training data\n",
    "X_3 = set_3.drop(columns = ['Chosen'])\n",
    "scaler_3 = StandardScaler()\n",
    "X_3 = scaler_3.fit_transform(X_3)\n",
    "y_3 = set_3.Chosen\n",
    "# prepare training and testing samples\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y_3, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_3 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_3.fit(X_3_train, y_3_train)\n",
    "\n",
    "# y_pred_3 = reg_3.predict(X_3_test)\n",
    "print(reg_3.score(X_3_test, y_3_test))\n",
    "print(reg_3.coef_)\n",
    "print(reg_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 2 - group a\n",
    "\n",
    "# scale training data\n",
    "X_a2 = set_a2.drop(columns = ['Chosen'])\n",
    "scaler_a2 = StandardScaler()\n",
    "X_a2 = scaler_a2.fit_transform(X_a2)\n",
    "y_a2 = set_a2.Chosen\n",
    "# prepare training and testing samples\n",
    "X_a2_train, X_a2_test, y_a2_train, y_a2_test = train_test_split(X_a2, y_a2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_a2 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_a2.fit(X_a2_train, y_a2_train)\n",
    "\n",
    "# y_pred_a2 = reg_a2.predict(X_a2_test)\n",
    "print(reg_a2.score(X_a2_test, y_a2_test))\n",
    "print(reg_a2.coef_)\n",
    "print(reg_a2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 2 - group b\n",
    "\n",
    "# scale training data\n",
    "X_b2 = set_b2.drop(columns = ['Chosen'])\n",
    "scaler_b2 = StandardScaler()\n",
    "X_b2 = scaler_b2.fit_transform(X_b2)\n",
    "y_b2 = set_b2.Chosen\n",
    "# prepare training and testing samples\n",
    "X_b2_train, X_b2_test, y_b2_train, y_b2_test = train_test_split(X_b2, y_b2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_b2 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_b2.fit(X_b2_train, y_b2_train)\n",
    "\n",
    "# y_pred_b2 = reg_b2.predict(X_b2_test)\n",
    "print(reg_b2.score(X_b2_test, y_b2_test))\n",
    "print(reg_b2.coef_)\n",
    "print(reg_b2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 2 - unified\n",
    "\n",
    "# scale training data\n",
    "X_2 = set_2.drop(columns = ['Chosen'])\n",
    "scaler_2 = StandardScaler()\n",
    "X_2 = scaler_2.fit_transform(X_2)\n",
    "y_2 = set_2.Chosen\n",
    "# prepare training and testing samples\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_2 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_2.fit(X_2_train, y_2_train)\n",
    "\n",
    "# y_pred_2 = reg_2.predict(X_2_test)\n",
    "print(reg_2.score(X_2_test, y_2_test))\n",
    "print(reg_2.coef_)\n",
    "print(reg_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 1 - group a\n",
    "\n",
    "# scale training data\n",
    "X_a1 = set_a1.drop(columns = ['Chosen'])\n",
    "scaler_a1 = StandardScaler()\n",
    "X_a1 = scaler_a1.fit_transform(X_a1)\n",
    "y_a1 = set_a1.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_a1_train, X_a1_test, y_a1_train, y_a1_test = train_test_split(X_a1, y_a1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_a1 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_a1.fit(X_a1_train, y_a1_train)\n",
    "\n",
    "# y_pred_a1 = reg_a1.predict(X_a1_test)\n",
    "print(reg_a1.score(X_a1_test, y_a1_test))\n",
    "print(reg_a1.coef_)\n",
    "print(reg_a1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 1 - group b\n",
    "\n",
    "# scale training data\n",
    "X_b1 = set_b1.drop(columns = ['Chosen'])\n",
    "scaler_b1 = StandardScaler()\n",
    "X_b1 = scaler_b1.fit_transform(X_b1)\n",
    "y_b1 = set_b1.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_b1_train, X_b1_test, y_b1_train, y_b1_test = train_test_split(X_b1, y_b1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_b1 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_b1.fit(X_b1_train, y_b1_train)\n",
    "\n",
    "# y_pred_b1 = reg_b1.predict(X_b1_test)\n",
    "print(reg_b1.score(X_b1_test, y_b1_test))\n",
    "print(reg_b1.coef_)\n",
    "print(reg_b1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 1 - unified\n",
    "\n",
    "# scale training data\n",
    "X_1 = set_1.drop(columns = ['Chosen'])\n",
    "scaler_1 = StandardScaler()\n",
    "X_1 = scaler_1.fit_transform(X_1)\n",
    "y_1 = set_1.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y_1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_1 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_1.fit(X_1_train, y_1_train)\n",
    "\n",
    "# y_pred_1 = reg_1.predict(X_1_test)\n",
    "print(reg_1.score(X_1_test, y_1_test))\n",
    "print(reg_1.coef_)\n",
    "print(reg_1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 0 - group a\n",
    "\n",
    "# scale training data\n",
    "X_a0 = set_a0.drop(columns = ['Chosen'])\n",
    "scaler_a0 = StandardScaler()\n",
    "X_a0 = scaler_a0.fit_transform(X_a0)\n",
    "y_a0 = set_a0.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_a0_train, X_a0_test, y_a0_train, y_a0_test = train_test_split(X_a0, y_a0, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_a0 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_a0.fit(X_a0_train, y_a0_train)\n",
    "\n",
    "# y_pred_a0 = reg_a5.predict(X_a5_test)\n",
    "print(reg_a0.score(X_a0_test, y_a0_test))\n",
    "print(reg_a0.coef_)\n",
    "print(reg_a0.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 0 - group b\n",
    "\n",
    "# scale training data\n",
    "X_b0 = set_b0.drop(columns = ['Chosen'])\n",
    "scaler_b0 = StandardScaler()\n",
    "X_b0 = scaler_b0.fit_transform(X_b0)\n",
    "y_b0 = set_b0.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_b0_train, X_b0_test, y_b0_train, y_b0_test = train_test_split(X_b0, y_b0, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_b0 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_b0.fit(X_b0_train, y_b0_train)\n",
    "\n",
    "# y_pred_b0 = reg_b0.predict(X_b0_test)\n",
    "print(reg_b0.score(X_b0_test, y_b0_test))\n",
    "print(reg_b0.coef_)\n",
    "print(reg_b0.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression solver 0 - unified\n",
    "\n",
    "# scale training data\n",
    "X_0 = set_0.drop(columns = ['Chosen'])\n",
    "scaler_0 = StandardScaler()\n",
    "X_0 = scaler_0.fit_transform(X_0)\n",
    "y_0 = set_0.Chosen\n",
    "\n",
    "# prepare training and testing samples\n",
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(X_0, y_0, test_size = 0.2, random_state = 0)\n",
    "\n",
    "reg_0 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs', max_iter = 1000, multi_class = 'ovr')\n",
    "\n",
    "reg_0.fit(X_0_train, y_0_train)\n",
    "\n",
    "# y_pred_0 = reg_0.predict(X_0_test)\n",
    "print(reg_0.score(X_0_test, y_0_test))\n",
    "print(reg_0.coef_)\n",
    "print(reg_0.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show comparison table\n",
    "compare.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between familiarity and length, streets, topo, turns\n",
    "fam_length = compare[['Familiarity', 'Path length']]\n",
    "print(fam_length.corr())\n",
    "fam_streets = compare[['Familiarity', 'Streets']]\n",
    "print(fam_streets.corr())\n",
    "fam_topo = compare[['Familiarity', 'Topo_length']]\n",
    "print(fam_topo.corr())\n",
    "fam_turns = compare[['Familiarity', 'Turns']]\n",
    "print(fam_turns.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate per-path averages\n",
    "chosen_a = set_a5.loc[lambda df: df['Chosen'] == 1, :]\n",
    "avg_a = chosen_a.mean(axis = 0, numeric_only = True)\n",
    "chosen_b = set_b5.loc[lambda df: df['Chosen'] == 1, :]\n",
    "avg_b = chosen_b.mean(axis = 0, numeric_only = True)\n",
    "chosen_u = set_5.loc[lambda df: df['Chosen'] == 1, :]\n",
    "avg_u = chosen_u.mean(axis = 0, numeric_only = True)\n",
    "print(avg_a.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# averages of weights by rank - 1st, 2nd, etc.\n",
    "\n",
    "# avg_angle_rank_a\n",
    "print(\"Average angle rank - path A:\", avg_a[3])\n",
    "# avg_angle_rank_b\n",
    "print(\"Average angle rank - path B:\", avg_b[3])\n",
    "# avg_angle_rank_u\n",
    "print(\"Average angle rank - unified:\", avg_u[3])\n",
    "\n",
    "# avg_slope_rank_a\n",
    "print(\"Average slope rank - path A:\", avg_a[4])\n",
    "# avg_slope_rank_b\n",
    "print(\"Average slope rank - path B:\", avg_b[4])\n",
    "# avg_slope_rank_u\n",
    "print(\"Average slope rank - unified:\", avg_u[4])\n",
    "\n",
    "# avg_distance_rank_a\n",
    "print(\"Average distance rank - path A:\", avg_a[5])\n",
    "# avg_distance_rank_b\n",
    "print(\"Average distance rank - path B:\", avg_b[5])\n",
    "# avg_distance_rank_u\n",
    "print(\"Average distance rank - unified:\", avg_u[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# averages along a path - slope, angle, distance\n",
    "\n",
    "# avg_angle_a\n",
    "print(\"Average angle - path A:\", avg_a[0])\n",
    "# avd_angle_b\n",
    "print(\"Average angle - path B:\", avg_b[0])\n",
    "# avd_angle_u\n",
    "print(\"Average angle - unified:\", avg_u[0])\n",
    "\n",
    "# avg_slope_a\n",
    "print(\"Average slope - path A:\", avg_a[1])\n",
    "# avg_slope_b\n",
    "print(\"Average slope - path B:\", avg_b[1])\n",
    "# avg_slope_u\n",
    "print(\"Average slope - unified:\", avg_u[1])\n",
    "\n",
    "# avg_distance_a\n",
    "print(\"Average distance - path A:\", avg_a[2])\n",
    "# avg_distance_b\n",
    "print(\"Average distance - path B:\", avg_b[2])\n",
    "# avg_distance_u\n",
    "print(\"Average distance - unified:\", avg_u[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
